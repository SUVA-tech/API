{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SUVA-tech/API/blob/main/Chatbot_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Configure the API key\n",
        "genai.configure(api_key=\"AIzaSyCdFkS-IAjpHNUoRIPhFs1jvdQe5P9AmVc\")\n",
        "\n",
        "# Function to load and preview Excel data\n",
        "def load_excel_data(file_path):\n",
        "    # Load the Excel file into a DataFrame\n",
        "    data = pd.read_excel(file_path)\n",
        "    # Display the first few rows as a preview\n",
        "    #preview = data.tail()  # Adjust the number of rows if needed\n",
        "    #print(\"Excel Data Preview:\")\n",
        "    #print(preview)\n",
        "    # Convert the entire DataFrame to a readable string format for the prompt\n",
        "    data_context = data.to_string(index=False)\n",
        "    return data_context\n",
        "\n",
        "# Function to send a request to the model\n",
        "def send_request(chat, context, question):\n",
        "    try:\n",
        "        # Combine context and question into a single prompt\n",
        "        prompt = f\"Here is the data:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
        "        response = chat.send_message(prompt)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred:\", e)\n",
        "        time.sleep(5)  # Wait before retrying\n",
        "        return None\n",
        "\n",
        "# Main function to load data, format it, preview it, and ask a query\n",
        "def ask_model_with_excel(file_path, question):\n",
        "    # Load Excel data, format it, and print a preview\n",
        "    data_context = load_excel_data(file_path)\n",
        "\n",
        "    # Start a chat with the model\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "    chat = model.start_chat()\n",
        "\n",
        "    # Send the request with the data context and question\n",
        "    response = send_request(chat, data_context, question)\n",
        "\n",
        "    if response:\n",
        "        # Extract and print the answer from the model's response\n",
        "        answer = response.candidates[0].content.parts[0].text\n",
        "        print(\"\\nAnswer:\", answer)\n",
        "    else:\n",
        "        print(\"No response received.\")\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/content/Walmart -GCT - Phase 2 Sandbox login credentials. 3rd Oct.xlsx\"  # Replace with the path to your Excel file\n",
        "\n",
        "question = \"What is the login credentials for Suvathy ?\"  # Example question\n",
        "ask_model_with_excel(file_path, question)"
      ],
      "metadata": {
        "id": "NzRWncQEOVsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "67cc3d78-d02e-4fc2-d8f6-5b7407b1f94f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: Suvathy A's login credentials are:\n",
            "\n",
            "* **Login ID:** unextwalmartlearner15\n",
            "* **Password:** Walmartunex$#45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Configure the API key\n",
        "genai.configure(api_key=\"AIzaSyCdFkS-IAjpHNUoRIPhFs1jvdQe5P9AmVc\")\n",
        "\n",
        "# Function to load and preview Excel data\n",
        "def load_excel_data(file_path):\n",
        "    # Load the Excel file into a DataFrame\n",
        "    data = pd.read_excel(file_path)\n",
        "    # Convert the entire DataFrame to a readable string format for the prompt\n",
        "    data_context = data.to_string(index=False)\n",
        "    return data_context\n",
        "\n",
        "# Function to send a request to the model\n",
        "def send_request(chat, context, question):\n",
        "    try:\n",
        "        # Combine context and question into a single prompt\n",
        "        prompt = f\"Here is the data:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
        "        response = chat.send_message(prompt)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred:\", e)\n",
        "        time.sleep(5)  # Wait before retrying\n",
        "        return None\n",
        "\n",
        "# Main function to load data, format it, preview it, and ask multiple questions\n",
        "def ask_model_with_excel(file_path, questions):\n",
        "    # Load Excel data, format it, and print a preview\n",
        "    data_context = load_excel_data(file_path)\n",
        "\n",
        "    # Start a chat with the model\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "    chat = model.start_chat()\n",
        "\n",
        "    # Iterate over the list of questions and send each one to the model\n",
        "    for question in questions:\n",
        "        response = send_request(chat, data_context, question)\n",
        "\n",
        "        if response:\n",
        "            # Extract and print the answer from the model's response\n",
        "            answer = response.candidates[0].content.parts[0].text\n",
        "            print(f\"\\nQuestion: {question}\\nAnswer: {answer}\")\n",
        "        else:\n",
        "            print(f\"No response received for question: {question}\")\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/content/Walmart -GCT - Phase 2 Sandbox login credentials. 3rd Oct.xlsx\"  # Replace with the path to your Excel file\n",
        "\n",
        "# List of questions to ask in a single run\n",
        "questions = [\n",
        "    \"What are the columns in it?\",\n",
        "    \"How many rows are there?\",\n",
        "    \"What is the data type of each column?\"\n",
        "]\n",
        "\n",
        "ask_model_with_excel(file_path, questions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "46Te_4beZcRf",
        "outputId": "2d65dba2-d3bc-4949-fbdc-90bd1099d251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: What are the columns in it?\n",
            "Answer: The columns are:\n",
            "\n",
            "* SL #\n",
            "* Candidate Id\n",
            "* Candidate Name\n",
            "* Primary Email\n",
            "* Login ID\n",
            "* Password\n",
            "* Unnamed: 1  (Appears to be empty/unused)\n",
            "* Unnamed: 2  (Appears to be empty/unused)\n",
            "* Unnamed: 3  (Contains the end date in the first row, otherwise empty/unused)\n",
            "* Unnamed: 4  (Appears to be empty/unused)\n",
            "* Unnamed: 5  (Appears to be empty/unused) \n",
            "\n",
            "The first three rows also contain information spread across some of these \"Unnamed\" columns, specifically the start date and URL, but these aren't really structured data within the table itself.\n",
            "\n",
            "\n",
            "Question: How many rows are there?\n",
            "Answer: There are 18 rows in the data, including the three header rows (title, start/end date, URL) and the 15 data rows for candidates/faculty.\n",
            "\n",
            "\n",
            "Question: What is the data type of each column?\n",
            "Answer: * **SL #:** Integer (or numeric)\n",
            "* **Candidate Id:** Integer (or numeric)\n",
            "* **Candidate Name:** String (text)\n",
            "* **Primary Email:** String (text)\n",
            "* **Login ID:** String (text)\n",
            "* **Password:** String (text)\n",
            "* **Unnamed: 1, Unnamed: 2, Unnamed: 4, Unnamed: 5:**  These would likely be treated as string columns by default, even though they largely contain NaN (Not a Number/null) values.\n",
            "* **Unnamed: 3:**  String (text) - due to the presence of the date string in the first row, even though other entries are NaN.\n",
            "\n",
            "\n",
            "It's important to note that if this data were loaded into a program like Pandas in Python, NaN values would typically be represented by a floating-point NaN value, so the Unnamed columns might be inferred as float64.  The specific data type might depend on how the data is loaded and the software used.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "# Configure the API key\n",
        "genai.configure(api_key=\"AIzaSyCdFkS-IAjpHNUoRIPhFs1jvdQe5P9AmVc\")\n",
        "\n",
        "# Function to load and preview Excel data\n",
        "def load_excel_data(file_path):\n",
        "    # Load the Excel file into a DataFrame\n",
        "    data = pd.read_excel(file_path)\n",
        "    # Convert the entire DataFrame to a readable string format for the prompt\n",
        "    data_context = data.to_string(index=False)\n",
        "    return data_context\n",
        "\n",
        "# Function to send a request to the model\n",
        "def send_request(chat, context, question):\n",
        "    try:\n",
        "        # Combine context and question into a single prompt\n",
        "        prompt = f\"Here is the data:\\n\\n{context}\\n\\nQuestion: {question}\"\n",
        "        response = chat.send_message(prompt)\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        print(\"Error occurred:\", e)\n",
        "        time.sleep(5)  # Wait before retrying\n",
        "        return None\n",
        "\n",
        "# Main function to load data and interact with multiple questions\n",
        "def interactive_ask_model_with_excel(file_path):\n",
        "    # Load Excel data and format it\n",
        "    data_context = load_excel_data(file_path)\n",
        "\n",
        "    # Start a chat with the model\n",
        "    model = genai.GenerativeModel(model_name=\"gemini-1.5-pro\")\n",
        "    chat = model.start_chat()\n",
        "\n",
        "    print(\"Interactive mode: Ask your questions about the Excel data. Type 'exit' to stop.\")\n",
        "\n",
        "    while True:\n",
        "        # Prompt the user to enter a question\n",
        "        question = input(\"\\nEnter your question: \")\n",
        "\n",
        "        # Check if the user wants to exit\n",
        "        if question.lower() == 'exit':\n",
        "            print(\"Ending the session.\")\n",
        "            break\n",
        "\n",
        "        # Send the request with the data context and question\n",
        "        response = send_request(chat, data_context, question)\n",
        "\n",
        "        if response:\n",
        "            # Extract and print the answer from the model's response\n",
        "            answer = response.candidates[0].content.parts[0].text\n",
        "            print(\"\\nAnswer:\", answer)\n",
        "        else:\n",
        "            print(\"No response received. Try again.\")\n",
        "\n",
        "# Example usage\n",
        "file_path = \"/content/Walmart -GCT - Phase 2 Sandbox login credentials. 3rd Oct.xlsx\"  # Replace with the path to your Excel file\n",
        "interactive_ask_model_with_excel(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZEsfdj7aDWV",
        "outputId": "bc4939a9-046a-4e53-8544-07845cc08b4c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Interactive mode: Ask your questions about the Excel data. Type 'exit' to stop.\n",
            "\n",
            "Enter your question: exit\n",
            "Ending the session.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxZFdFB03PAsFpV6Jry3GG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}